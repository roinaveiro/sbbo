{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d879f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roinaveiro/miniconda/envs/tf-sbbo/lib/python3.8/site-packages/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n",
      "/Users/roinaveiro/miniconda/envs/tf-sbbo/lib/python3.8/site-packages/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.inheritance.inherit_check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import gpflow\n",
    "from gpflow.mean_functions import Constant\n",
    "from gpflow.utilities import positive, print_summary\n",
    "from gpflow.utilities.ops import broadcasting_elementwise\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from rdkit.Chem import AllChem, Descriptors, MolFromSmiles\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.contamination import Contamination\n",
    "from src.latin_square import LatinSquare\n",
    "\n",
    "from src.models.GPr import GPr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b27b0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngboost import NGBRegressor\n",
    "from ngboost.distns import Exponential, Normal\n",
    "from ngboost.scores import LogScore, CRPScore\n",
    "\n",
    "from ngboost.distns.normal import Normal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LassoCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bd847a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanimoto(gpflow.kernels.Kernel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # We constrain the value of the kernel variance to be positive when it's being optimised\n",
    "        self.variance = gpflow.Parameter(1.0, transform=positive())\n",
    "\n",
    "    def K(self, X, X2=None):\n",
    "        \"\"\"\n",
    "        Compute the Tanimoto kernel matrix σ² * ((<x, y>) / (||x||^2 + ||y||^2 - <x, y>))\n",
    "        :param X: N x D array\n",
    "        :param X2: M x D array. If None, compute the N x N kernel matrix for X.\n",
    "        :return: The kernel matrix of dimension N x M\n",
    "        \"\"\"\n",
    "        if X2 is None:\n",
    "            X2 = X\n",
    "\n",
    "        Xs = tf.reduce_sum(tf.square(X), axis=-1)  # Squared L2-norm of X\n",
    "        X2s = tf.reduce_sum(tf.square(X2), axis=-1)  # Squared L2-norm of X2\n",
    "        outer_product = tf.tensordot(X, X2, [[-1], [-1]])  # outer product of the matrices X and X2\n",
    "\n",
    "        # Analogue of denominator in Tanimoto formula\n",
    "\n",
    "        denominator = -outer_product + broadcasting_elementwise(tf.add, Xs, X2s)\n",
    "\n",
    "        return self.variance * outer_product/denominator\n",
    "\n",
    "    def K_diag(self, X):\n",
    "        \"\"\"\n",
    "        Compute the diagonal of the N x N kernel matrix of X\n",
    "        :param X: N x D array\n",
    "        :return: N x 1 array\n",
    "        \"\"\"\n",
    "        return tf.fill(tf.shape(X)[:-1], tf.squeeze(self.variance))\n",
    "    \n",
    "def transform_data(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Apply feature scaling to the data. Return the standardised train and\n",
    "    test sets together with the scaler object for the target values.\n",
    "    :param X_train: input train data\n",
    "    :param y_train: train labels\n",
    "    :param X_test: input test data\n",
    "    :param y_test: test labels\n",
    "    :return: X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled, y_scaler\n",
    "    \"\"\"\n",
    "\n",
    "    x_scaler = StandardScaler()\n",
    "    X_train_scaled = x_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = x_scaler.transform(X_test)\n",
    "    y_scaler = StandardScaler()\n",
    "    y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "    y_test_scaled = y_scaler.transform(y_test)\n",
    "\n",
    "    return X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae0f9149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = LatinSquare(n=2000)\n",
    "opt = Contamination(n=300, lamda=0.0001)\n",
    "X = opt.X\n",
    "y = opt.y\n",
    "\n",
    "test_set_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf8f630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_size, random_state=0)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "#  We standardise the outputs but leave the inputs unchanged\n",
    "\n",
    "_, y_train, _, y_test, y_scaler = transform_data(X_train, y_train, X_test, y_test)\n",
    "\n",
    "X_train = X_train.astype(np.float64)\n",
    "X_test = X_test.astype(np.float64)\n",
    "\n",
    "k = Tanimoto()\n",
    "# k = gpflow.kernels.Matern32()\n",
    "m = gpflow.models.GPR(data=(X_train, y_train), mean_function=Constant(np.mean(y_train)), kernel=k, noise_variance=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e2cbfa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -2.14777 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │  1.75273 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  1e-05   │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "opt = gpflow.optimizers.Scipy()\n",
    "opt.minimize(m.training_loss, m.trainable_variables)\n",
    "print_summary(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "243655c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_var = m.predict_f(X_test)\n",
    "y_pred = y_scaler.inverse_transform(y_pred)\n",
    "y_test = y_scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "85c1bf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33090509, 0.29323645, 0.27569958, 0.38293804, 0.55186894,\n",
       "       0.27450514, 0.2212626 , 0.44540456, 0.21540746, 0.19931773,\n",
       "       0.79404407, 0.30834906, 0.55250438, 0.26161385, 0.27008172,\n",
       "       0.35400501, 0.23665507, 0.39911424, 0.24153515, 0.33799247,\n",
       "       0.20009657, 0.21065968, 0.35196697, 0.35798925, 0.29759923,\n",
       "       0.28474165, 0.45911288, 0.25661039, 0.54810662, 0.34935706,\n",
       "       0.40646474, 0.16215061, 0.45060432, 0.2244177 , 0.29138425,\n",
       "       0.37851139, 0.23634718, 0.3916373 , 0.23237996, 0.213299  ,\n",
       "       0.25476047, 0.4281434 , 0.54622334, 0.35817801, 0.33660736,\n",
       "       0.28664215, 0.28735927, 0.30046277, 0.31844842, 0.30786249,\n",
       "       0.3742284 , 0.2792149 , 0.20159599, 0.32068754, 0.32576645,\n",
       "       0.26963602, 0.27178021, 0.32344859, 0.22670815, 0.34615359])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_var.numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2a1814ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.09073869, 1.93821278, 0.91175986, 1.505309  , 0.88965641,\n",
       "       1.78275912, 1.79515858, 1.70707869, 2.17148008, 1.991912  ,\n",
       "       0.89773583, 1.8760215 , 1.11139583, 1.31169085, 1.5700163 ,\n",
       "       2.08098649, 1.85624904, 1.61443037, 2.36991535, 1.18689895,\n",
       "       1.97695272, 1.69813417, 1.78279465, 1.40736081, 1.24530878,\n",
       "       1.81928552, 0.92609013, 1.37285989, 1.09087017, 1.73976604,\n",
       "       1.9695438 , 2.45363282, 1.27723201, 1.72117032, 2.03265628,\n",
       "       1.44424161, 1.94960097, 1.12968579, 1.58115391, 1.76411155,\n",
       "       1.34638383, 1.34069672, 1.13082344, 1.21581243, 1.51069622,\n",
       "       2.13063891, 1.24830599, 1.85815959, 1.60402279, 1.66929078,\n",
       "       1.47929668, 2.21103365, 2.19302947, 2.08984454, 1.21441771,\n",
       "       1.90840089, 0.96639795, 1.75756909, 2.03785557, 1.46645775])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e00c52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train RMSE (Standardised): 0.000 nm\n",
      "Train RMSE: 0.000 nm\n",
      "\n",
      "Test R^2: 0.615\n",
      "Test RMSE: 0.291 nm\n",
      "Test MAE: 0.229 nm\n"
     ]
    }
   ],
   "source": [
    "y_pred_train, _ = m.predict_f(X_train)\n",
    "train_rmse_stan = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "train_rmse = np.sqrt(mean_squared_error(y_scaler.inverse_transform(y_train), y_scaler.inverse_transform(y_pred_train)))\n",
    "print(\"\\nTrain RMSE (Standardised): {:.3f} nm\".format(train_rmse_stan))\n",
    "print(\"Train RMSE: {:.3f} nm\".format(train_rmse))\n",
    "\n",
    "\n",
    "# Output R^2, RMSE and MAE on the test set\n",
    "score = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTest R^2: {:.3f}\".format(score))\n",
    "print(\"Test RMSE: {:.3f} nm\".format(rmse))\n",
    "print(\"Test MAE: {:.3f} nm\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fe94675",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_confidence_list = np.argsort(y_var, axis=0).flatten()\n",
    "rmse_confidence_list = np.zeros((len(y_test) ))\n",
    "mae_confidence_list = np.zeros((len(y_test) ))\n",
    "\n",
    "for k in range(len(y_test)):\n",
    "\n",
    "    # Construct the RMSE error for each level of confidence\n",
    "\n",
    "    conf = ranked_confidence_list[0:k+1]\n",
    "    rmse = np.sqrt(mean_squared_error(y_test[conf], y_pred[conf]))\n",
    "    rmse_confidence_list[k] = rmse\n",
    "\n",
    "    # Construct the MAE error for each level of confidence\n",
    "\n",
    "    mae = mean_absolute_error(y_test[conf], y_pred[conf])\n",
    "    mae_confidence_list[k] = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ece933ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32720557, 0.23349615, 0.28425053, 0.46789571, 0.45803177,\n",
       "       0.41953734, 0.40448906, 0.39195142, 0.38403203, 0.41864875,\n",
       "       0.40127959, 0.38476374, 0.3985938 , 0.38416665, 0.37140984,\n",
       "       0.36127439, 0.3505675 , 0.34473185, 0.34376501, 0.33892446,\n",
       "       0.3311232 , 0.33137435, 0.3488987 , 0.34190943, 0.33554708,\n",
       "       0.32935321, 0.32620114, 0.32163998, 0.31622359, 0.3152653 ,\n",
       "       0.31846924, 0.32091539, 0.32398087, 0.31922162, 0.31650347,\n",
       "       0.31374797, 0.3095397 , 0.31094055, 0.31012004, 0.31179078,\n",
       "       0.3094629 , 0.30595304, 0.30424809, 0.30186017, 0.29939892,\n",
       "       0.29659863, 0.29950446, 0.3074105 , 0.30429667, 0.30123867,\n",
       "       0.29915559, 0.3034244 , 0.30087118, 0.29886285, 0.29682502,\n",
       "       0.29965957, 0.2972244 , 0.29548255, 0.29298284, 0.29054057])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_confidence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56add60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
