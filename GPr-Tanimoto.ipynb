{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d879f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow\n",
    "from gpflow.mean_functions import Constant\n",
    "from gpflow.utilities import positive, print_summary\n",
    "from gpflow.utilities.ops import broadcasting_elementwise\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from rdkit.Chem import AllChem, Descriptors, MolFromSmiles\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.contamination import Contamination\n",
    "from src.latin_square import LatinSquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "57c8f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = 'CON'\n",
    "learner = 'NGBlin'\n",
    "acqfun  = 'EI'\n",
    "search  = 'MH'\n",
    "epsilon = 0.0\n",
    "n_exp   = np.arange(1,9)\n",
    "\n",
    "header = '''#!/bin/bash\n",
    "#$ -q teano\n",
    "#$ -pe smp 10\n",
    "#$ -j yes\n",
    "#$ -cwd\n",
    "\n",
    "# Load anaconda malware environment\n",
    "conda activate base\n",
    "\n",
    "# Run the executable\n",
    "'''\n",
    "\n",
    "tail = '''\n",
    "\n",
    "# Deactivate anaconda environment\n",
    "conda deactivate\n",
    "'''\n",
    "\n",
    "text = []\n",
    "for i in n_exp:\n",
    "    current = (f\"python -u run.py --problem {problem} \"  \n",
    "               f\"--learner {learner} --acqfun {acqfun} \" \n",
    "               f\"--niters 500 --search {search} \" \n",
    "               f\"--epsilon {epsilon} --nexp {i} \" \n",
    "               f\"> exp_{i}_{problem}_{learner}_o{search}_af{acqfun}.out\")\n",
    "    \n",
    "    current = header + current + tail\n",
    "    \n",
    "    with open(f'experiment{i}.sub', 'w') as f:\n",
    "        f.write(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fb8300ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#$ -q teano\n",
      "#$ -pe smp 10\n",
      "#$ -j yes\n",
      "#$ -cwd\n",
      "\n",
      "# Load anaconda malware environment\n",
      "conda activate base\n",
      "\n",
      "# Run the executable\n",
      "\n",
      "# Deactivate anaconda environment\n",
      "conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "header = '''#!/bin/bash\n",
    "#$ -q teano\n",
    "#$ -pe smp 10\n",
    "#$ -j yes\n",
    "#$ -cwd\n",
    "\n",
    "# Load anaconda malware environment\n",
    "conda activate base\n",
    "\n",
    "# Run the executable\n",
    "'''\n",
    "\n",
    "tail = '''\n",
    "# Deactivate anaconda environment\n",
    "conda deactivate\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3bd847a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanimoto(gpflow.kernels.Kernel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # We constrain the value of the kernel variance to be positive when it's being optimised\n",
    "        self.variance = gpflow.Parameter(1.0, transform=positive())\n",
    "\n",
    "    def K(self, X, X2=None):\n",
    "        \"\"\"\n",
    "        Compute the Tanimoto kernel matrix σ² * ((<x, y>) / (||x||^2 + ||y||^2 - <x, y>))\n",
    "        :param X: N x D array\n",
    "        :param X2: M x D array. If None, compute the N x N kernel matrix for X.\n",
    "        :return: The kernel matrix of dimension N x M\n",
    "        \"\"\"\n",
    "        if X2 is None:\n",
    "            X2 = X\n",
    "\n",
    "        Xs = tf.reduce_sum(tf.square(X), axis=-1)  # Squared L2-norm of X\n",
    "        X2s = tf.reduce_sum(tf.square(X2), axis=-1)  # Squared L2-norm of X2\n",
    "        outer_product = tf.tensordot(X, X2, [[-1], [-1]])  # outer product of the matrices X and X2\n",
    "\n",
    "        # Analogue of denominator in Tanimoto formula\n",
    "\n",
    "        denominator = -outer_product + broadcasting_elementwise(tf.add, Xs, X2s)\n",
    "\n",
    "        return self.variance * outer_product/denominator\n",
    "\n",
    "    def K_diag(self, X):\n",
    "        \"\"\"\n",
    "        Compute the diagonal of the N x N kernel matrix of X\n",
    "        :param X: N x D array\n",
    "        :return: N x 1 array\n",
    "        \"\"\"\n",
    "        return tf.fill(tf.shape(X)[:-1], tf.squeeze(self.variance))\n",
    "    \n",
    "def transform_data(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Apply feature scaling to the data. Return the standardised train and\n",
    "    test sets together with the scaler object for the target values.\n",
    "    :param X_train: input train data\n",
    "    :param y_train: train labels\n",
    "    :param X_test: input test data\n",
    "    :param y_test: test labels\n",
    "    :return: X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled, y_scaler\n",
    "    \"\"\"\n",
    "\n",
    "    x_scaler = StandardScaler()\n",
    "    X_train_scaled = x_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = x_scaler.transform(X_test)\n",
    "    y_scaler = StandardScaler()\n",
    "    y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "    y_test_scaled = y_scaler.transform(y_test)\n",
    "\n",
    "    return X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ae0f9149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = LatinSquare(n=2000)\n",
    "opt = Contamination(n=2000, lamda=0.0001)\n",
    "X = opt.X\n",
    "y = opt.y\n",
    "\n",
    "test_set_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3df1e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_size, random_state=0)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "#  We standardise the outputs but leave the inputs unchanged\n",
    "\n",
    "_, y_train, _, y_test, y_scaler = transform_data(X_train, y_train, X_test, y_test)\n",
    "\n",
    "X_train = X_train.astype(np.float64)\n",
    "X_test = X_test.astype(np.float64)\n",
    "\n",
    "k = Tanimoto()\n",
    "m = gpflow.models.GPR(data=(X_train, y_train), mean_function=Constant(np.mean(y_train)), kernel=k, noise_variance=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a1f77dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -2.73748 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │  1.35498 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.02286 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "opt = gpflow.optimizers.Scipy()\n",
    "opt.minimize(m.training_loss, m.trainable_variables)\n",
    "print_summary(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4f9036d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_var = m.predict_f(X_test)\n",
    "y_pred = y_scaler.inverse_transform(y_pred)\n",
    "y_test = y_scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a1c0f441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train RMSE (Standardised): 0.068 nm\n",
      "Train RMSE: 0.033 nm\n",
      "\n",
      "Test R^2: 0.893\n",
      "Test RMSE: 0.161 nm\n",
      "Test MAE: 0.126 nm\n"
     ]
    }
   ],
   "source": [
    "y_pred_train, _ = m.predict_f(X_train)\n",
    "train_rmse_stan = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "train_rmse = np.sqrt(mean_squared_error(y_scaler.inverse_transform(y_train), y_scaler.inverse_transform(y_pred_train)))\n",
    "print(\"\\nTrain RMSE (Standardised): {:.3f} nm\".format(train_rmse_stan))\n",
    "print(\"Train RMSE: {:.3f} nm\".format(train_rmse))\n",
    "\n",
    "\n",
    "# Output R^2, RMSE and MAE on the test set\n",
    "score = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTest R^2: {:.3f}\".format(score))\n",
    "print(\"Test RMSE: {:.3f} nm\".format(rmse))\n",
    "print(\"Test MAE: {:.3f} nm\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d4079091",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_confidence_list = np.argsort(y_var, axis=0).flatten()\n",
    "rmse_confidence_list = np.zeros((len(y_test) ))\n",
    "mae_confidence_list = np.zeros((len(y_test) ))\n",
    "\n",
    "for k in range(len(y_test)):\n",
    "\n",
    "    # Construct the RMSE error for each level of confidence\n",
    "\n",
    "    conf = ranked_confidence_list[0:k+1]\n",
    "    rmse = np.sqrt(mean_squared_error(y_test[conf], y_pred[conf]))\n",
    "    rmse_confidence_list[k] = rmse\n",
    "\n",
    "    # Construct the MAE error for each level of confidence\n",
    "\n",
    "    mae = mean_absolute_error(y_test[conf], y_pred[conf])\n",
    "    mae_confidence_list[k] = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "43ca546f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00819251, 0.02899606, 0.02497636, 0.16000292, 0.14567414,\n",
       "       0.13298667, 0.14030063, 0.13340461, 0.1348033 , 0.1333208 ,\n",
       "       0.13058016, 0.12897997, 0.14928521, 0.14397815, 0.14420755,\n",
       "       0.14378376, 0.13984755, 0.14226892, 0.14685822, 0.14676362,\n",
       "       0.14980991, 0.14678895, 0.14359473, 0.14081814, 0.1535156 ,\n",
       "       0.15187388, 0.1498225 , 0.15518232, 0.15248332, 0.1531791 ,\n",
       "       0.15159734, 0.153925  , 0.15161663, 0.15059126, 0.15404465,\n",
       "       0.15215139, 0.15731668, 0.15744057, 0.15541381, 0.15364253,\n",
       "       0.15458796, 0.15381623, 0.15581077, 0.15570536, 0.15485688,\n",
       "       0.15358384, 0.1583823 , 0.16232103, 0.16804936, 0.16657359,\n",
       "       0.16510623, 0.16418924, 0.16743004, 0.16629797, 0.1657063 ,\n",
       "       0.16422226, 0.16445646, 0.16334954, 0.16451783, 0.16375416,\n",
       "       0.16245935, 0.16214178, 0.16115942, 0.16085964, 0.15994537,\n",
       "       0.16618483, 0.16510811, 0.163936  , 0.16577508, 0.16561974,\n",
       "       0.16460005, 0.1658246 , 0.16569187, 0.16460938, 0.1635103 ,\n",
       "       0.16280119, 0.16271532, 0.1628462 , 0.16188372, 0.16518011,\n",
       "       0.16480557, 0.16379967, 0.16283332, 0.16628087, 0.16625679,\n",
       "       0.16541385, 0.16519649, 0.1643563 , 0.16361677, 0.16301255,\n",
       "       0.16881108, 0.16919796, 0.16847589, 0.16793246, 0.16706099,\n",
       "       0.17166804, 0.17099732, 0.1705613 , 0.17167754, 0.17090063,\n",
       "       0.17026394, 0.17033008, 0.16950268, 0.16980293, 0.16989161,\n",
       "       0.17182038, 0.17170247, 0.17118014, 0.17042566, 0.16981022,\n",
       "       0.16904368, 0.16834891, 0.16769222, 0.16773764, 0.16706509,\n",
       "       0.16670088, 0.16608379, 0.16584285, 0.16514459, 0.16619612,\n",
       "       0.16611146, 0.16576052, 0.16536053, 0.16515177, 0.16478836,\n",
       "       0.16440275, 0.16377534, 0.16407543, 0.16392164, 0.16347144,\n",
       "       0.16540316, 0.16481517, 0.16422862, 0.16556235, 0.16523223,\n",
       "       0.16525372, 0.16591544, 0.16531326, 0.16474828, 0.16428833,\n",
       "       0.16379187, 0.16357181, 0.16316853, 0.16262154, 0.16308302,\n",
       "       0.16269686, 0.16221253, 0.1617066 , 0.1627315 , 0.16219387,\n",
       "       0.16174844, 0.16121604, 0.16095041, 0.1606803 , 0.16030008,\n",
       "       0.15997869, 0.16146328, 0.1611142 , 0.16060676, 0.16014139,\n",
       "       0.15968392, 0.1612653 , 0.16119138, 0.1607322 , 0.16026167,\n",
       "       0.16182931, 0.16186497, 0.16147878, 0.16228329, 0.16186228,\n",
       "       0.16152871, 0.16288729, 0.16330638, 0.16330636, 0.16410521,\n",
       "       0.16363834, 0.16388186, 0.16345013, 0.16304874, 0.16283384,\n",
       "       0.16291422, 0.1624699 , 0.16208732, 0.16215826, 0.16172054,\n",
       "       0.16167608, 0.16155726, 0.16205909, 0.16167222, 0.16162391,\n",
       "       0.16120431, 0.16136087, 0.16254185, 0.16331462, 0.16291839,\n",
       "       0.16270286, 0.16270328, 0.16240906, 0.16201421, 0.16181262,\n",
       "       0.16219177, 0.16185114, 0.1618329 , 0.16148843, 0.16149554,\n",
       "       0.16111658, 0.16074003, 0.16038595, 0.16103755, 0.16066734,\n",
       "       0.16040074, 0.16038798, 0.16049887, 0.16091756, 0.16059491,\n",
       "       0.16023148, 0.16033743, 0.16000235, 0.15963741, 0.15927746,\n",
       "       0.15897226, 0.15906369, 0.1588326 , 0.15873158, 0.15841228,\n",
       "       0.15838606, 0.15839936, 0.1581078 , 0.15784922, 0.15774383,\n",
       "       0.15743516, 0.157109  , 0.1567731 , 0.15648406, 0.15627591,\n",
       "       0.15607196, 0.15583356, 0.1555728 , 0.15524787, 0.1549652 ,\n",
       "       0.15539687, 0.15507989, 0.15494637, 0.15464031, 0.15433927,\n",
       "       0.15421531, 0.15434432, 0.15426565, 0.1541968 , 0.15398413,\n",
       "       0.15368106, 0.15339331, 0.15318941, 0.1528876 , 0.15264763,\n",
       "       0.15235012, 0.15214675, 0.15185554, 0.1516823 , 0.15140111,\n",
       "       0.15113428, 0.15128316, 0.15100305, 0.15099868, 0.15072074,\n",
       "       0.15192562, 0.15221151, 0.15192746, 0.15262988, 0.15251282,\n",
       "       0.15246242, 0.15218544, 0.15195186, 0.1523161 , 0.15204818,\n",
       "       0.15180597, 0.15340769, 0.15313316, 0.15289254, 0.1526285 ,\n",
       "       0.15322823, 0.15302458, 0.1527829 , 0.15278817, 0.15288251,\n",
       "       0.15262637, 0.1524231 , 0.1521675 , 0.15211975, 0.15205184,\n",
       "       0.15204201, 0.15314534, 0.15289918, 0.15315548, 0.15306969,\n",
       "       0.15335416, 0.15310441, 0.15291101, 0.15265838, 0.15254649,\n",
       "       0.15229832, 0.15205064, 0.15185179, 0.15195849, 0.15183   ,\n",
       "       0.1515911 , 0.15160012, 0.15153095, 0.15138176, 0.1518985 ,\n",
       "       0.15259838, 0.15352424, 0.15334586, 0.1532054 , 0.15304738,\n",
       "       0.15329663, 0.15390409, 0.15366749, 0.15342959, 0.15429995,\n",
       "       0.15419058, 0.15430672, 0.15454444, 0.15468825, 0.15457465,\n",
       "       0.15460453, 0.1558509 , 0.15616846, 0.15596184, 0.15578071,\n",
       "       0.15554535, 0.15533145, 0.1554345 , 0.15535967, 0.15517204,\n",
       "       0.15499325, 0.15481616, 0.15465557, 0.15483278, 0.1546553 ,\n",
       "       0.15442854, 0.15425838, 0.15418034, 0.15448486, 0.15513038,\n",
       "       0.15500838, 0.1547861 , 0.15465469, 0.15443849, 0.15455052,\n",
       "       0.15450855, 0.15487643, 0.15476306, 0.15455365, 0.15536888,\n",
       "       0.15523884, 0.15503141, 0.15481476, 0.15466377, 0.15445337,\n",
       "       0.15490163, 0.15468968, 0.15447721, 0.15434204, 0.1547474 ,\n",
       "       0.15460111, 0.15652668, 0.15632987, 0.15921353, 0.15899823,\n",
       "       0.1590747 , 0.1592078 , 0.15909385, 0.1590189 , 0.15903811,\n",
       "       0.15893118, 0.15882867, 0.15892501, 0.15872661, 0.15891176,\n",
       "       0.15874209, 0.15854844, 0.15854475, 0.15839734, 0.15820578,\n",
       "       0.15801432, 0.15792242, 0.1578222 , 0.15767229, 0.15828974,\n",
       "       0.15839546, 0.1582089 , 0.15829155, 0.15898715, 0.15907114,\n",
       "       0.1593432 , 0.15915218, 0.15898745, 0.15956593, 0.16096311])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_confidence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bac971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
